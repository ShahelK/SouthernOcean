{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shahelkhan/anaconda2/lib/python2.7/site-packages/nbformat/current.py:19: UserWarning: nbformat.current is deprecated.\n",
      "\n",
      "- use nbformat for read/write/validate public API\n",
      "- use nbformat.vX directly to composing notebooks of a particular version\n",
      "\n",
      "  \"\"\")\n"
     ]
    }
   ],
   "source": [
    "import io, os, sys, types\n",
    "from IPython import get_ipython\n",
    "from nbformat import current\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "\n",
    "def find_notebook(fullname, path=None):\n",
    "    \"\"\"find a notebook, given its fully qualified name and an optional path\n",
    "\n",
    "    This turns \"foo.bar\" into \"foo/bar.ipynb\"\n",
    "    and tries turning \"Foo_Bar\" into \"Foo Bar\" if Foo_Bar\n",
    "    does not exist.\n",
    "    \"\"\"\n",
    "    name = fullname.rsplit('.', 1)[-1]\n",
    "    if not path:\n",
    "        path = ['']\n",
    "    for d in path:\n",
    "        nb_path = os.path.join(d, name + \".ipynb\")\n",
    "        if os.path.isfile(nb_path):\n",
    "            return nb_path\n",
    "        # let import Notebook_Name find \"Notebook Name.ipynb\"\n",
    "        nb_path = nb_path.replace(\"_\", \" \")\n",
    "        if os.path.isfile(nb_path):\n",
    "            return nb_path\n",
    "\n",
    "\n",
    "class NotebookLoader(object):\n",
    "    \"\"\"Module Loader for Jupyter Notebooks\"\"\"\n",
    "    def __init__(self, path=None):\n",
    "        self.shell = InteractiveShell.instance()\n",
    "        self.path = path\n",
    "\n",
    "    def load_module(self, fullname):\n",
    "        \"\"\"import a notebook as a module\"\"\"\n",
    "        path = find_notebook(fullname, self.path)\n",
    "\n",
    "        print (\"importing Jupyter notebook from %s\" % path)\n",
    "\n",
    "        # load the notebook object\n",
    "        with io.open(path, 'r', encoding='utf-8') as f:\n",
    "            nb = current.read(f, 'json')\n",
    "\n",
    "\n",
    "        # create the module and add it to sys.modules\n",
    "        # if name in sys.modules:\n",
    "        #    return sys.modules[name]\n",
    "        mod = types.ModuleType(fullname)\n",
    "        mod.__file__ = path\n",
    "        mod.__loader__ = self\n",
    "        mod.__dict__['get_ipython'] = get_ipython\n",
    "        sys.modules[fullname] = mod\n",
    "\n",
    "        # extra work to ensure that magics that would affect the user_ns\n",
    "        # actually affect the notebook module's ns\n",
    "        save_user_ns = self.shell.user_ns\n",
    "        self.shell.user_ns = mod.__dict__\n",
    "\n",
    "        try:\n",
    "            for cell in nb.worksheets[0].cells:\n",
    "                if cell.cell_type == 'code' and cell.language == 'python':\n",
    "                    # transform the input to executable Python\n",
    "                    code = self.shell.input_transformer_manager.transform_cell(cell.input)\n",
    "                    # run the code in themodule\n",
    "                    exec(code, mod.__dict__)\n",
    "        finally:\n",
    "            self.shell.user_ns = save_user_ns\n",
    "        return mod\n",
    "\n",
    "\n",
    "class NotebookFinder(object):\n",
    "    \"\"\"Module finder that locates Jupyter Notebooks\"\"\"\n",
    "    def __init__(self):\n",
    "        self.loaders = {}\n",
    "\n",
    "    def find_module(self, fullname, path=None):\n",
    "        nb_path = find_notebook(fullname, path)\n",
    "        if not nb_path:\n",
    "            return\n",
    "\n",
    "        key = path\n",
    "        if path:\n",
    "            # lists aren't hashable\n",
    "            key = os.path.sep.join(path)\n",
    "\n",
    "        if key not in self.loaders:\n",
    "            self.loaders[key] = NotebookLoader(path)\n",
    "        return self.loaders[key]\n",
    "\n",
    "sys.meta_path.append(NotebookFinder())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from Load.ipynb\n",
      "importing Jupyter notebook from Print.ipynb\n",
      "('Printing runtime = ', 0.5786349999999998, ' s')\n",
      "('Load runtime = ', 0.20259099999999997, ' s')\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Aug 22 14:14:47 2018\n",
    "\n",
    "@author: shahelkhan\n",
    "\n",
    "Bic.py\n",
    "\n",
    "Purpose:\n",
    "    - Calculate the most appropriate number of components for the GMM process.\n",
    "    - Do this by testing different training datasets selecting\n",
    "    - loop over these 50 times and calculate a mean and standard deviation for the \n",
    "\n",
    "\"\"\"\n",
    "# Import the various modules necessary\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn import mixture\n",
    "from sklearn import decomposition\n",
    "from math import log10, floor\n",
    "\n",
    "import Load\n",
    "import Print\n",
    "\n",
    "start_time = time.clock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main(address, filename_raw_data, subsample_bic, repeat_bic, max_groups, grid_bic,\\\n",
    "         conc_bic, size_bic, n_dimen, fraction_nan_samples, fraction_nan_depths):\n",
    "    \n",
    "    bic_many = np.ones((repeat_bic,max_groups-1)) # Need to use (max_groups-1) as the bic runs from 1 to max_groups \n",
    "    n_lowest_array = np.zeros(repeat_bic)\n",
    "    n_comp_array = None\n",
    "    for i in range(0,repeat_bic):\n",
    "        print(\"Starting \", i)\n",
    "        bic = bic_oneRun(address, filename_raw_data, subsample_bic, repeat_bic, max_groups, grid_bic,\\\n",
    "                   conc_bic, size_bic, n_dimen, fraction_nan_samples, fraction_nan_depths)\n",
    "        bic_many[i,:] = bic[0]\n",
    "        n_lowest_array[i] = bic[1]\n",
    "        if i == 0 :\n",
    "            n_comp_array = bic[2]\n",
    "        del bic\n",
    "        print(\"finished \", i)\n",
    "        \n",
    "    \n",
    "    # bic_many shape (repeat, n_comp_array)\n",
    "\n",
    "    bic_stand = preprocessing.StandardScaler()\n",
    "    bic_stand.fit(bic_many)\n",
    "    bic_mean = bic_stand.mean_\n",
    "    bic_stdev = np.sqrt(bic_stand.var_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate the most appropriate number of components from the bic_scores\n",
    "def round_sig(x, x_2, sig=2):\n",
    "    return round(x, sig-int(floor(log10(abs(x_2))))-1)\n",
    "\n",
    "    n_stand = preprocessing.StandardScaler()\n",
    "    n_stand.fit(n_lowest_array.reshape(-1,1))\n",
    "    n_mean = n_stand.mean_[0]\n",
    "    n_stdev = np.sqrt(n_stand.var_[0])\n",
    "\n",
    "    n_mean = round_sig(n_mean, n_stdev)\n",
    "    n_stdev = round_sig(n_stdev, n_stdev)\n",
    "    \n",
    "    # Alternative way of calculating the minimum number of components\n",
    "    min_index = np.where(bic_mean==bic_mean.min())[0]\n",
    "    n_min = (n_comp_array[min_index])[0]\n",
    "\n",
    "    # Print to file\n",
    "    Print.printBIC(address, repeat_bic, bic_many, bic_mean, bic_stdev, n_mean, n_stdev, n_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bic_oneRun(address, filename_raw_data, subsample_bic, repeat_bic, max_groups, grid_bic,\\\n",
    "         conc_bic, size_bic, n_dimen, fraction_nan_samples, fraction_nan_depths):\n",
    "\n",
    "    # Load the training data\n",
    "    lon_train, lat_train, Tint_train, varTrain_centre, Sint_train, varTime_train \\\n",
    "            = None, None, None, None, None, None\n",
    "    lon_train, lat_train, Tint_train, varTrain_centre, Sint_train, varTime_train \\\n",
    "        = Load.main(address, filename_raw_data, None, subsample_bic, False,\\\n",
    "         False, grid_bic, conc_bic, None, None, None,\\\n",
    "         fraction_nan_samples, fraction_nan_depths, run_Bic=True)\n",
    "        \n",
    "\n",
    "    # Calculate PCA\n",
    "    pca, X_pca_train = None, None\n",
    "    pca = decomposition.PCA(n_components = n_dimen)     # Initialise PCA object\n",
    "    pca.fit(varTrain_centre)                         # Fit the PCA to the training data\n",
    "    X_pca_train = pca.transform(varTrain_centre) \n",
    "    del pca\n",
    "    \n",
    "    # Run BIC for GMM with different number of components\n",
    "    # bic_values contains the array of scores for the different n_comp\n",
    "    # n_lowest is the lowest n for each repeat\n",
    "    # n_comp_array is from 0 to max_groups in integers\n",
    "    bic_values, n_lowest, n_comp_array = None, None, None\n",
    "    bic_values, n_lowest, n_comp_array = bic_calculate(X_pca_train, max_groups)\n",
    "\n",
    "    return bic_values, n_lowest, n_comp_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Bic runtime = ', 0.4057599999999999, ' s')\n"
     ]
    }
   ],
   "source": [
    "def bic_calculate(X, max_groups):\n",
    "#    print(\"BIC X shape = \",X.shape)\n",
    "    X = X.reshape(-1,1)\n",
    "#    print(\"BIC X.reshape shape = \", X.shape)\n",
    "    lowest_bic, bic_score = np.infty, []\n",
    "    n_components_range = np.arange(1, max_groups)\n",
    "    for n_components in n_components_range:\n",
    "#        print(\"BIC n_comp = \",n_components)\n",
    "        gmm = mixture.GaussianMixture(n_components = n_components, covariance_type = 'diag')\n",
    "        gmm.fit(X)\n",
    "        bic_score.append(gmm.bic(X))\n",
    "        if bic_score[-1] < lowest_bic:\n",
    "            lowest_bic = bic_score[-1]\n",
    "            lowest_n = n_components\n",
    "    bic_score = np.asarray(bic_score).reshape(1,-1)\n",
    "    return bic_score, lowest_n, n_components_range\n",
    "\n",
    "print('Bic runtime = ', time.clock() - start_time,' s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
