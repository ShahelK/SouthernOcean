{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Aug 16 15:03:46 2018\n",
    "\n",
    "@author: shahelkhan\n",
    "\n",
    "Print.py\n",
    "\n",
    "Purpose:\n",
    "    - Print the data to files is csv format\n",
    "    - Reload data for later use\n",
    "    \n",
    "\"\"\"\n",
    "import time\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "start_time = time.clock()\n",
    "\n",
    "separator = ','"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Depth Printing\n",
    "def printDepth(address, run, depth):\n",
    "    print(\"Print.printDepth\")\n",
    "    filename = address+\"Data_store/Info/Depth_retained.csv\"\n",
    "    file = open(filename,'w')\n",
    "    data = depth.reshape(len(depth),1)\n",
    "    writer = csv.DictWriter(file, fieldnames = ['Depth'], delimiter = separator)\n",
    "    writer.writeheader()\n",
    "    writer = csv.writer(file, delimiter=separator)\n",
    "    for line in data:\n",
    "        writer.writerow(line)\n",
    "    file.close() \n",
    "    \n",
    "def readDepth(address, run):\n",
    "    print(\"Print.readDepth\")\n",
    "    filename = address+\"Data_store/Info/Depth_retained.csv\"\n",
    "    depth = None\n",
    "    head_number = 1\n",
    "    csvfile = np.genfromtxt(filename, delimiter=\",\",skip_header=head_number)\n",
    "    depth = csvfile[:]\n",
    "    return depth\n",
    "\n",
    "# Col_reduced Printing\n",
    "def printColreduced(address, run, col_reduced):\n",
    "    print(\"Print.printColreduced\")\n",
    "    filename = address+\"Data_store/Info/Col_reduced.csv\"\n",
    "    file = open(filename,'w')\n",
    "    data = [col_reduced]\n",
    "    writer = csv.DictWriter(file, fieldnames = ['Col_reduced'], delimiter = separator)\n",
    "    writer.writeheader()\n",
    "    writer = csv.writer(file, delimiter=separator)\n",
    "    writer.writerow(data)\n",
    "    file.close()\n",
    "    \n",
    "def readColreduced(address, run):\n",
    "    print(\"Print.readColreduced\")\n",
    "    filename = address+\"Data_store/Info/Col_reduced.csv\"\n",
    "    col_reduced = None\n",
    "    head_number = 1\n",
    "    csvfile = np.genfromtxt(filename, delimiter=\",\",skip_header=head_number)\n",
    "    col_reduced = int(csvfile)\n",
    "    print(\"col_reduced = \", col_reduced)\n",
    "    return col_reduced\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# BIC printing and loading\n",
    "def printBIC(address, repeat_bic, bic_many, bic_mean, bic_stdev, n_mean, n_stdev, n_min):\n",
    "    print(\"Print.printBIC\")\n",
    "    print(\"SHAPE OF BIC MANY = \", bic_many.shape)\n",
    "    data, columns = None, None\n",
    "    \n",
    "    # This section prints the information on components, minimum scores and means\n",
    "    filename = address + \"Data_store/Info/BIC_Info.csv\"\n",
    "    file = open(filename, 'w')\n",
    "    columns = np.column_stack((n_mean, n_stdev, n_min))\n",
    "    data = columns\n",
    "    writer = csv.DictWriter(file, fieldnames = ['n_mean_from_ave_nmin_individual','n_stdev','n_min_from_bic_mean'], delimiter = separator)\n",
    "    writer.writeheader()\n",
    "    writer = csv.writer(file, delimiter=separator)\n",
    "    for line in data:\n",
    "        writer.writerow(line)    \n",
    "    file.close()\n",
    "    del filename, file\n",
    "    \n",
    "    # This section prints the bic scores\n",
    "    for r in range(repeat_bic):\n",
    "        filename = address + \"Data_store/Info/BIC_r\"+str(int(r))+\".csv\"\n",
    "        file = open(filename,'w')\n",
    "        data, columns = None, None\n",
    "        columns = np.column_stack((bic_many[r,:], bic_mean, bic_stdev))\n",
    "        data = columns\n",
    "        writer = csv.DictWriter(file, fieldnames = ['bic_many'+str(int(r)),'bic_mean','bic_stdev'], delimiter = separator)\n",
    "        writer.writeheader()\n",
    "        writer = csv.writer(file, delimiter=separator)\n",
    "        for line in data:\n",
    "            writer.writerow(line)    \n",
    "        file.close()\n",
    "        del filename, file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readBIC(address, repeat_bic):\n",
    "    # This section reads the information on components, minimum scores and means\n",
    "    n_mean, n_stdev, n_min = None, None, None\n",
    "    head_number = 1\n",
    "    filename = address+\"Data_store/Info/BIC_Info.csv\"\n",
    "    csvfile = np.genfromtxt(filename, delimiter=\",\",skip_header=head_number)\n",
    "    n_mean  = csvfile[0]\n",
    "    n_stdev = csvfile[1]\n",
    "    n_min   = csvfile[2]\n",
    "\n",
    "    # Read the bic_scores\n",
    "    bic_r, bic_many, bic_mean, bic_stdev = None, None, None, None\n",
    "    head_number = 1\n",
    "\n",
    "    for r in range(repeat_bic):\n",
    "        filename = address+\"Data_store/Info/BIC_r\"+str(int(r))+\".csv\"\n",
    "        \n",
    "        csvfile = np.genfromtxt(filename, delimiter=\",\",skip_header=head_number)\n",
    "        \n",
    "        if r == 0:\n",
    "            bic_mean     = csvfile[:,1]\n",
    "            bic_stdev     = csvfile[:,2]\n",
    "\n",
    "        bic_r    = csvfile[:,0]\n",
    "\n",
    "        if r == 0:\n",
    "            bic_many        = bic_r.reshape(1, bic_r.size)\n",
    "        else:\n",
    "            bic_r = bic_r.reshape(1,bic_r.size)\n",
    "            bic_many = np.vstack([bic_many, bic_r])\n",
    "            \n",
    "    print(\"SHAPE OF BIC MANY AFTER READING = \", bic_many.shape)\n",
    "\n",
    "    return bic_many, bic_mean, bic_stdev, n_mean, n_stdev, n_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load Printing\n",
    "def printLoadToFile(address, run, lon, lat, Tint, var_centre, Sint, varTime, \\\n",
    "                          depth ):\n",
    "    print(\"Print.printLoadToFile\")\n",
    "    i = 0 \n",
    "    for d in depth:\n",
    "        filename = address+\"Data_store/CentredAndUncentred/CentredAndUncentred_depth\"+str(int(d))+\".csv\"\n",
    "\n",
    "        file = open(filename,'w')\n",
    "        columns= np.column_stack((lon, lat, Tint[:,i], var_centre[:,i], Sint[:,i], varTime))\n",
    "        data = columns\n",
    "        writer = csv.DictWriter(file, fieldnames = ['lon','lat','Tint_'+str(int(d)),'Tint_centred','Sint','Time'], delimiter = separator)\n",
    "        writer.writeheader()\n",
    "        writer = csv.writer(file, delimiter=separator)\n",
    "        for line in data:\n",
    "            writer.writerow(line)    \n",
    "        file.close()\n",
    "        del filename, file\n",
    "        \n",
    "        i = i + 1\n",
    "        \n",
    "def printLoadToFile_Train(address, run, lon_train, lat_train, Tint_train, \\\n",
    "                          varTrain_centre, Sint_train, varTime_train,\\\n",
    "                          depth ):\n",
    "    print(\"Print.printLoadToFile_Train\")\n",
    "    i = 0 \n",
    "    for d in depth:\n",
    "        filename_train = address+\"Data_store/CentredAndUncentred_Train/CentredAndUncentred_Train_depth\"+str(int(d))+\".csv\"        \n",
    "\n",
    "        file_train = open(filename_train,'w')\n",
    "        columns_train = np.column_stack((lon_train, lat_train, Tint_train[:,i], varTrain_centre[:,i], Sint_train[:,i], varTime_train))\n",
    "        data_train = columns_train\n",
    "        writer = csv.DictWriter(file_train, fieldnames = ['lon_train','lat_train','VAR_train_'+str(int(d)),'Var_train_centred','Sint_train','Time_train'], delimiter = separator)\n",
    "        writer.writeheader()\n",
    "        writer = csv.writer(file_train, delimiter=separator)    \n",
    "        for line in data_train:\n",
    "            writer.writerow(line)\n",
    "        file_train.close() \n",
    "        del filename_train, file_train\n",
    "        \n",
    "        i = i + 1\n",
    "        \n",
    "def printLoadToFile_Test(address, run, lon_test, lat_test, Tint_test, \\\n",
    "                                varTest_centre, Sint_test, varTime_test, depth):\n",
    "    print(\"Print.printLoadToFile_Test\")\n",
    "    i = 0 \n",
    "    for d in depth:\n",
    "        filename_test = address+\"Data_store/CentredAndUncentred_Test/CentredAndUncentred_Test_depth\"+str(int(d))+\".csv\"        \n",
    "\n",
    "        file_test = open(filename_test,'w')\n",
    "        columns_test = np.column_stack((lon_test, lat_test, Tint_test[:,i], varTest_centre[:,i], Sint_test[:,i], varTime_test))\n",
    "        data_test = columns_test\n",
    "        writer = csv.DictWriter(file_test, fieldnames = ['lon_test','lat_test','VAR_test_'+str(int(d)),'Var_test_centred','Sint_test','Time_test'], delimiter = separator)\n",
    "        writer.writeheader()\n",
    "        writer = csv.writer(file_test, delimiter=separator)    \n",
    "        for line in data_test:\n",
    "            writer.writerow(line)\n",
    "        file_test.close() \n",
    "        del filename_test, file_test\n",
    "        \n",
    "        i = i + 1\n",
    "    \n",
    "def readLoadFromFile(address, run, depth):\n",
    "    print(\"Print.readLoadFromFile\")\n",
    "    lon, lat, Tint, var, Sint, varTime = None, None, None, None, None, None\n",
    "    head_number = 1\n",
    "    i = 0\n",
    "    for d in depth:\n",
    "#        print(i)\n",
    "        filename = address+\"Data_store/CentredAndUncentred/CentredAndUncentred_depth\"+str(int(d))+\".csv\"\n",
    "        \n",
    "        csvfile = np.genfromtxt(filename, delimiter=\",\",skip_header=head_number)\n",
    "        if i == 0:\n",
    "            lon     = csvfile[:,0]\n",
    "            lat     = csvfile[:,1]\n",
    "            varTime = csvfile[:,5]\n",
    "\n",
    "        Tint    = csvfile[:,2]\n",
    "        var     = csvfile[:,3]\n",
    "        Sint    = csvfile[:,4]\n",
    "\n",
    "        if i == 0:\n",
    "            Tint_array      = Tint.reshape(Tint.size,1)\n",
    "            Sint_array      = Sint.reshape(Sint.size,1)\n",
    "            X_array         = var.reshape(var.size,1)\n",
    "        else:\n",
    "            Tint = Tint.reshape(Tint.size,1)\n",
    "            Sint = Sint.reshape(Sint.size,1)\n",
    "            Tint_array = np.hstack([Tint_array, Tint])\n",
    "            Sint_array = np.hstack([Sint_array, Sint])\n",
    "            \n",
    "            X = var.reshape(var.size,1)\n",
    "            X_array = np.hstack([X_array, X])\n",
    "        i = i + 1   \n",
    "\n",
    "    return lon, lat, Tint_array, X_array, Sint_array, varTime\n",
    "\n",
    "def readLoadFromFile_Train(address, run, depth):\n",
    "    print(\"Print.readLoadFromFile_Train\")\n",
    "    lon_train, lat_train, Tint_train, varTrain, Sint_train, varTime_train = None, None, None, None, None, None\n",
    "    head_number = 1\n",
    "    i = 0\n",
    "    for d in depth:\n",
    "#        print(i)\n",
    "        filename_train = address+\"Data_store/CentredAndUncentred_Train/CentredAndUncentred_Train_depth\"+str(int(d))+\".csv\"\n",
    "\n",
    "        csvfile_train = np.genfromtxt(filename_train, delimiter=\",\",skip_header=head_number)\n",
    "        if i == 0:\n",
    "            lon_train     = csvfile_train[:,0]\n",
    "            lat_train     = csvfile_train[:,1]\n",
    "            varTime_train = csvfile_train[:,5]\n",
    "\n",
    "        Tint_train    = csvfile_train[:,2]\n",
    "        varTrain     = csvfile_train[:,3]\n",
    "        Sint_train    = csvfile_train[:,4]\n",
    "    \n",
    "        if i == 0:\n",
    "            Tint_train_array = Tint_train.reshape(Tint_train.size,1)\n",
    "            Sint_train_array = Sint_train.reshape(Sint_train.size,1)\n",
    "            X_train_array   = varTrain.reshape(varTrain.size,1)\n",
    "        else:\n",
    "            Tint_train = Tint_train.reshape(Tint_train.size,1)\n",
    "            Sint_train = Sint_train.reshape(Sint_train.size,1)\n",
    "            Tint_train_array = np.hstack([Tint_train_array, Tint_train])\n",
    "            Sint_train_array = np.hstack([Sint_train_array, Sint_train]) \n",
    "            \n",
    "            X_train = varTrain.reshape(varTrain.size,1)\n",
    "            X_train_array = np.hstack([X_train_array, X_train])\n",
    "        \n",
    "        i = i + 1\n",
    "\n",
    "    return lon_train,lat_train, Tint_train_array, X_train_array, \\\n",
    "            Sint_train_array, varTime_train\n",
    "            \n",
    "def readLoadFromFile_Test(address, run, depth):\n",
    "    print(\"Print.readLoadFromFile_Test\")\n",
    "    lon_test, lat_test, Tint_test, varTest, Sint_test, varTime_test = None, None, None, None, None, None\n",
    "    head_number = 1\n",
    "    i = 0\n",
    "    for d in depth:\n",
    "#        print(i)\n",
    "        filename_test = address+\"Data_store/CentredAndUncentred_Test/CentredAndUncentred_Test_depth\"+str(int(d))+\".csv\"\n",
    "\n",
    "        csvfile_test = np.genfromtxt(filename_test, delimiter=\",\",skip_header=head_number)\n",
    "        if i == 0:\n",
    "            lon_test     = csvfile_test[:,0]\n",
    "            lat_test     = csvfile_test[:,1]\n",
    "            varTime_test = csvfile_test[:,5]\n",
    "\n",
    "        Tint_test    = csvfile_test[:,2]\n",
    "        varTest     = csvfile_test[:,3]\n",
    "        Sint_test    = csvfile_test[:,4]\n",
    "    \n",
    "        if i == 0:\n",
    "            Tint_test_array = Tint_test.reshape(Tint_test.size,1)\n",
    "            Sint_test_array = Sint_test.reshape(Sint_test.size,1)\n",
    "            X_test_array   = varTest.reshape(varTest.size,1)\n",
    "        else:\n",
    "            Tint_test = Tint_test.reshape(Tint_test.size,1)\n",
    "            Sint_test = Sint_test.reshape(Sint_test.size,1)\n",
    "            Tint_test_array = np.hstack([Tint_test_array, Tint_test])\n",
    "            Sint_test_array = np.hstack([Sint_test_array, Sint_test]) \n",
    "            \n",
    "            X_test = varTest.reshape(varTest.size,1)\n",
    "            X_test_array = np.hstack([X_test_array, X_test])\n",
    "        \n",
    "        i = i + 1\n",
    "\n",
    "    return lon_test, lat_test, Tint_test_array, X_test_array, \\\n",
    "            Sint_test_array, varTime_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PCA Printing\n",
    "def printPCAToFile(address, run, lon, lat, X_pca, varTime, col_reduced):\n",
    "    print(\"Print.printPCAToFile\")\n",
    "    for d in range(col_reduced):\n",
    "        filename = address+\"Data_store/PCA/PCA_reddepth\"+str(d)+\".csv\"        \n",
    "\n",
    "        file = open(filename, 'w')\n",
    "        columns = np.column_stack((lon, lat, X_pca[:,d], varTime))\n",
    "        data = columns\n",
    "        writer = csv.DictWriter(file, fieldnames = ['lon','lat','VAR_'+str(int(d)),'Time'], delimiter = separator)\n",
    "        writer.writeheader()\n",
    "        writer = csv.writer(file, delimiter=separator)    \n",
    "        for line in data:\n",
    "            writer.writerow(line)\n",
    "        file.close() \n",
    "        del filename, file\n",
    "\n",
    "def printPCAToFile_Train(address, run, lon_train, lat_train, \\\n",
    "                                X_pca_train, varTime_train, col_reduced):\n",
    "    print(\"Print.printPCAToFile_Train\")\n",
    "    for d in range(col_reduced):\n",
    "        filename_train = address+\"Data_store/PCA_Train/PCA_Train_reddepth\"+str(d)+\".csv\"        \n",
    "\n",
    "        file_train = open(filename_train,'w')\n",
    "        columns_train = np.column_stack((lon_train, lat_train, X_pca_train[:,d], varTime_train))\n",
    "        data_train = columns_train\n",
    "        writer = csv.DictWriter(file_train, fieldnames = ['lon_train','lat_train','VAR_train_'+str(int(d)),'Time_train'], delimiter = separator)\n",
    "        writer.writeheader()\n",
    "        writer = csv.writer(file_train, delimiter=separator)    \n",
    "        for line in data_train:\n",
    "            writer.writerow(line)\n",
    "        file_train.close() \n",
    "        del filename_train, file_train\n",
    "\n",
    "def readPCAFromFile(address, run, col_reduced):\n",
    "    print(\"Print.readPCAFromFile\")\n",
    "    lon, lat, var, varTime= None, None, None, None\n",
    "    head_number = 1\n",
    "    for d in range(col_reduced):\n",
    "        filename = address+\"Data_store/PCA/PCA_reddepth\"+str(int(d))+\".csv\"\n",
    "\n",
    "        csvfile = np.genfromtxt(filename, delimiter=\",\",skip_header=head_number)\n",
    "        \n",
    "        if d == 0:\n",
    "            lon     = csvfile[:,0]\n",
    "            lat     = csvfile[:,1]\n",
    "            varTime = csvfile[:,3]\n",
    "\n",
    "        var     = csvfile[:,2]\n",
    "    \n",
    "        if d == 0:\n",
    "            X_array   = var.reshape(var.size,1)\n",
    "        else:\n",
    "            X = var.reshape(var.size,1)\n",
    "            X_array = np.hstack([X_array, X])\n",
    "#    print(\"X_array.shape = \", X_array.shape)\n",
    "#    print(lon.shape,lat.shape,varTime.shape)\n",
    "    \n",
    "    return lon, lat, X_array, varTime\n",
    "        \n",
    "def readPCAFromFile_Train(address, run, col_reduced):\n",
    "    print(\"Print.readPCAFromFile_Train\")\n",
    "    lon_train, lat_train, varTrain, varTime_train = None, None, None, None\n",
    "    head_number = 1\n",
    "    for d in range(col_reduced):\n",
    "        filename_train = address+\"Data_store/PCA_Train/PCA_Train_reddepth\"+str(int(d))+\".csv\"\n",
    "\n",
    "        csvfile_train = np.genfromtxt(filename_train, delimiter=\",\",skip_header=head_number)\n",
    "        \n",
    "        if d == 0:\n",
    "            lon_train     = csvfile_train[:,0]\n",
    "            lat_train     = csvfile_train[:,1]\n",
    "            varTime_train = csvfile_train[:,3]\n",
    "\n",
    "        varTrain     = csvfile_train[:,2]\n",
    "    \n",
    "        if d == 0:\n",
    "            X_train_array   = varTrain.reshape(varTrain.size,1)\n",
    "        else:\n",
    "            X_train = varTrain.reshape(varTrain.size,1)\n",
    "            X_train_array = np.hstack([X_train_array, X_train])\n",
    "#    print(\"X_train_array.shape = \", X_train_array.shape)\n",
    "#    print(lon_train.shape,lat_train.shape,varTime_train.shape)\n",
    "    \n",
    "    return lon_train, lat_train, X_train_array, varTime_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def printGMMclasses(address, run, class_number_array, gmm_weights, gmm_means,\\\n",
    "                    gmm_covariances, depth_array, space):\n",
    "    print(\"Print.printGMMclasses \"+space)\n",
    "    # space is either 'depth', 'reduced' or 'uncentred'\n",
    "    # depth_number is either col_reduced or len(depth)\n",
    "    i = 0\n",
    "    for d in depth_array:\n",
    "        filename_train = address+\"Data_store/GMM_classes_\"+space+\"/GMM_classes_\"+space+str(int(d))+\".csv\"        \n",
    "        if run != None:\n",
    "            filename_train = address+\"Data_store/GMM_classes_\"+space+\"/GMM_classes_\"+space+str(int(d))+\"_run\"+str(int(run))+\".csv\"        \n",
    "\n",
    "        file_train = open(filename_train,'w')\n",
    "        columns_train = np.column_stack((class_number_array, gmm_weights, gmm_means[:,i], gmm_covariances[:,i]))\n",
    "        data_train = columns_train\n",
    "        writer = csv.DictWriter(file_train, fieldnames = ['Class','Weights','Means_'+str(int(d)),'Covariances_'+str(int(d))], delimiter = separator)\n",
    "        writer.writeheader()\n",
    "        writer = csv.writer(file_train, delimiter=separator)    \n",
    "        for line in data_train:\n",
    "            writer.writerow(line)\n",
    "        file_train.close() \n",
    "        del filename_train, file_train\n",
    "        i = i + 1\n",
    "        \n",
    "def readGMMclasses(address, run, depth_array, space):\n",
    "    print(\"Print.readGMMclasses \"+space)\n",
    "    # space is either 'depth', 'reduced' or 'uncentred'\n",
    "    # depth_number is either col_reduced or len(depth)\n",
    "    gmm_weights, gmm_means_i, gmm_covariances_i = None, None, None\n",
    "    head_number = 1\n",
    "    i = 0\n",
    "    for d in depth_array:\n",
    "        filename_train = address+\"Data_store/GMM_classes_\"+space+\"/GMM_classes_\"+space+str(int(d))+\".csv\"        \n",
    "        if run != None:\n",
    "            filename_train = address+\"Data_store/GMM_classes_\"+space+\"/GMM_classes_\"+space+str(int(d))+\"_run\"+str(int(run))+\".csv\"     \n",
    "\n",
    "        csvfile_train = np.genfromtxt(filename_train, delimiter=\",\",skip_header=head_number)\n",
    "        \n",
    "        if i == 0:\n",
    "            gmm_weights     = csvfile_train[:,1]\n",
    "        # Note [:,0] would return the class number\n",
    "        gmm_means_i     = csvfile_train[:,2]\n",
    "        gmm_covariances_i = csvfile_train[:,3]\n",
    "        \n",
    "        if i == 0:\n",
    "            gmm_means   = gmm_means_i.reshape(gmm_means_i.size,1)\n",
    "            gmm_covariances   = gmm_covariances_i.reshape(gmm_covariances_i.size,1)\n",
    "        else:\n",
    "            gmm_means_i = gmm_means_i.reshape(gmm_means_i.size,1)\n",
    "            gmm_covariances_i = gmm_covariances_i.reshape(gmm_covariances_i.size,1)\n",
    "            gmm_means = np.hstack([gmm_means, gmm_means_i])\n",
    "            gmm_covariances = np.hstack([gmm_covariances, gmm_covariances_i])\n",
    "        i = i + 1\n",
    "#    print(\"gmm_means.shape = \", gmm_means.shape)\n",
    "#    print(\"gmm_covariances.shape = \", gmm_covariances.shape)\n",
    "#    print(gmm_weights.shape)\n",
    "    \n",
    "    return gmm_weights, gmm_means, gmm_covariances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def printLabels(address, run, lon, lat, varTime, labels):\n",
    "    print(\"Print.printLabels\")\n",
    "    filename = address+\"Data_store/Labels/Labels.csv\"\n",
    "    if run != None:\n",
    "        filename = address+\"Data_store/Labels/Labels_run\"+str(run)+\".csv\"        \n",
    "\n",
    "    file = open(filename,'w')\n",
    "    columns = np.column_stack(( lon, lat, varTime, labels ))\n",
    "    data = columns\n",
    "    writer = csv.DictWriter(file, fieldnames = ['lon','lat','varTime','label'], delimiter = separator)\n",
    "    writer.writeheader()\n",
    "    writer = csv.writer(file, delimiter=separator)    \n",
    "    for line in data:\n",
    "        writer.writerow(line)\n",
    "    file.close() \n",
    "    del filename, file\n",
    "    \n",
    "def readLabels(address,run):\n",
    "    print(\"Print.readLabels\")\n",
    "    head_number = 1\n",
    "    filename = address+\"Data_store/Labels/Labels.csv\"\n",
    "    if run != None:\n",
    "        filename = address+\"Data_store/Labels/Labels_run\"+str(run)+\".csv\"\n",
    "        \n",
    "    csvfile = np.genfromtxt(filename, delimiter=\",\",skip_header=head_number)\n",
    "    \n",
    "    lon, lat, varTime, labels = None, None, None, None\n",
    "    \n",
    "    lon = csvfile[:,0]\n",
    "    lat = csvfile[:,1]\n",
    "    varTime = csvfile[:,2]\n",
    "    labels = csvfile[:,3]\n",
    "    \n",
    "    return lon, lat, varTime, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def printPosteriorProb(address, run, lon, lat, varTime, post_prob, class_number_array):\n",
    "    print(\"Print.printPosteriorProb\")\n",
    "    i = 0\n",
    "    for class_number in class_number_array:\n",
    "        filename = address+\"Data_store/Probabilities/Post_prob_class\"+str(class_number)+\".csv\"\n",
    "        file = open(filename,'w')\n",
    "        columns = np.column_stack(( lon, lat, varTime, post_prob[:,i] ))\n",
    "        data = columns\n",
    "        writer = csv.DictWriter(file, fieldnames = ['lon','lat','varTime','post_prob_class_'+str(class_number)], delimiter = separator)\n",
    "        writer.writeheader()\n",
    "        writer = csv.writer(file, delimiter=separator)    \n",
    "        for line in data:\n",
    "            writer.writerow(line)\n",
    "        file.close() \n",
    "        del filename, file\n",
    "        i = i + 1\n",
    "        \n",
    "def readPosteriorProb(address,run,class_number_array):\n",
    "    print(\"Print.readPosteriorProb\")\n",
    "    head_number = 1\n",
    "    i = 0\n",
    "    post_prob = None\n",
    "    for class_number in class_number_array:\n",
    "        filename = address+\"Data_store/Probabilities/Post_prob_class\"+str(class_number)+\".csv\"\n",
    "\n",
    "        csvfile = np.genfromtxt(filename, delimiter=\",\",skip_header=head_number)\n",
    "        \n",
    "        lon, lat, varTime, post_prob_i = None, None, None, None\n",
    "        \n",
    "        if i == 0:\n",
    "            lon = csvfile[:,0]\n",
    "            lat = csvfile[:,1]\n",
    "            varTime = csvfile[:,2]\n",
    "        \n",
    "        post_prob_i = csvfile[:,3]\n",
    "\n",
    "        if i == 0:\n",
    "            post_prob  = post_prob_i.reshape(post_prob_i.size,1)\n",
    "        else:            \n",
    "            post_prob_i = post_prob_i.reshape(post_prob_i.size,1)\n",
    "            post_prob = np.hstack([post_prob, post_prob_i])\n",
    "        i = i + 1\n",
    "    \n",
    "    return lon, lat, varTime, post_prob\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def printReconstruction(address, run, lon, lat, X, XC, varTime, depth, isTrain):\n",
    "    print(\"Print.printReconstruction isTrain = \"+str(isTrain))\n",
    "    # isTrain is True or False\n",
    "    i = 0\n",
    "    for d in depth:\n",
    "        filename = address+\"Data_store/Reconstruction/Recon_depth\"+str(int(d))+\".csv\"\n",
    "        if isTrain:\n",
    "            filename = address+\"Data_store/Reconstruction_Train/Recon_Train_depth\"+str(int(d))+\".csv\"\n",
    "        file = open(filename,'w')\n",
    "        columns = np.column_stack(( lon, lat, X[:,i], XC[:,i], varTime ))\n",
    "        data = columns\n",
    "        writer = csv.DictWriter(file, fieldnames = ['lon','lat','X_'+str(int(d)), 'X_centred', 'varTime'], delimiter = separator)\n",
    "        writer.writeheader()\n",
    "        writer = csv.writer(file, delimiter=separator)    \n",
    "        for line in data:\n",
    "            writer.writerow(line)\n",
    "        file.close() \n",
    "        del filename, file\n",
    "        i = i + 1\n",
    "        \n",
    "def readReconstruction(address, run, depth, isTrain):\n",
    "    print(\"Print.readReconstruction isTrain = \"+str(isTrain))\n",
    "    # Function reads the Reconstructed XR, XRC, XR_Train, XRC_Train\n",
    "    head_number = 1\n",
    "    i = 0\n",
    "    for d in depth:\n",
    "        \n",
    "        filename = address+\"Data_store/Reconstruction/Recon_depth\"+str(int(d))+\".csv\"\n",
    "        if isTrain:\n",
    "            filename = address+\"Data_store/Reconstruction_Train/Recon_Train_depth\"+str(int(d))+\".csv\"\n",
    "\n",
    "        csvfile = np.genfromtxt(filename, delimiter=\",\",skip_header=head_number)\n",
    "        if i == 0:\n",
    "            lon     = csvfile[:,0]\n",
    "            lat     = csvfile[:,1]\n",
    "            varTime = csvfile[:,4]\n",
    "\n",
    "        var         = csvfile[:,2]\n",
    "        var_centred = csvfile[:,3]\n",
    "\n",
    "        if i == 0:\n",
    "            X_array_centred = var_centred.reshape(var_centred.size,1)\n",
    "            X_array         = var.reshape(var.size,1)\n",
    "        else:            \n",
    "            X = var.reshape(var.size,1)\n",
    "            X_array = np.hstack([X_array, X])\n",
    "            X_centred = var_centred.reshape(var_centred.size,1)\n",
    "            X_array_centred = np.hstack([X_array_centred, X_centred])\n",
    "            \n",
    "        i = i + 1   \n",
    "#        del Tint, Tint_train, Sint, Sint_train, var, X, varTrain, X_train\n",
    "\n",
    "#    print(\"X_array.shape = \", X_array.shape)\n",
    "#    print(\"Tint_array.shape = \", Tint_array.shape)\n",
    "#    print(\"Sint_array.shape = \", Sint_array.shape)\n",
    "    \n",
    "#    print(lon.shape,lat.shape,varTime.shape)\n",
    "    \n",
    "    return lon, lat, X_array, X_array_centred, varTime\n",
    "        \n",
    "    \n",
    "print('Printing runtime = ', time.clock() - start_time,' s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
