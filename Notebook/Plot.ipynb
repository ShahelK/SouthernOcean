{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shahelkhan/anaconda2/lib/python2.7/site-packages/nbformat/current.py:19: UserWarning: nbformat.current is deprecated.\n",
      "\n",
      "- use nbformat for read/write/validate public API\n",
      "- use nbformat.vX directly to composing notebooks of a particular version\n",
      "\n",
      "  \"\"\")\n"
     ]
    }
   ],
   "source": [
    "import io, os, sys, types\n",
    "from IPython import get_ipython\n",
    "from nbformat import current\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "\n",
    "def find_notebook(fullname, path=None):\n",
    "    \"\"\"find a notebook, given its fully qualified name and an optional path\n",
    "\n",
    "    This turns \"foo.bar\" into \"foo/bar.ipynb\"\n",
    "    and tries turning \"Foo_Bar\" into \"Foo Bar\" if Foo_Bar\n",
    "    does not exist.\n",
    "    \"\"\"\n",
    "    name = fullname.rsplit('.', 1)[-1]\n",
    "    if not path:\n",
    "        path = ['']\n",
    "    for d in path:\n",
    "        nb_path = os.path.join(d, name + \".ipynb\")\n",
    "        if os.path.isfile(nb_path):\n",
    "            return nb_path\n",
    "        # let import Notebook_Name find \"Notebook Name.ipynb\"\n",
    "        nb_path = nb_path.replace(\"_\", \" \")\n",
    "        if os.path.isfile(nb_path):\n",
    "            return nb_path\n",
    "\n",
    "\n",
    "class NotebookLoader(object):\n",
    "    \"\"\"Module Loader for Jupyter Notebooks\"\"\"\n",
    "    def __init__(self, path=None):\n",
    "        self.shell = InteractiveShell.instance()\n",
    "        self.path = path\n",
    "\n",
    "    def load_module(self, fullname):\n",
    "        \"\"\"import a notebook as a module\"\"\"\n",
    "        path = find_notebook(fullname, self.path)\n",
    "\n",
    "        print (\"importing Jupyter notebook from %s\" % path)\n",
    "\n",
    "        # load the notebook object\n",
    "        with io.open(path, 'r', encoding='utf-8') as f:\n",
    "            nb = current.read(f, 'json')\n",
    "\n",
    "\n",
    "        # create the module and add it to sys.modules\n",
    "        # if name in sys.modules:\n",
    "        #    return sys.modules[name]\n",
    "        mod = types.ModuleType(fullname)\n",
    "        mod.__file__ = path\n",
    "        mod.__loader__ = self\n",
    "        mod.__dict__['get_ipython'] = get_ipython\n",
    "        sys.modules[fullname] = mod\n",
    "\n",
    "        # extra work to ensure that magics that would affect the user_ns\n",
    "        # actually affect the notebook module's ns\n",
    "        save_user_ns = self.shell.user_ns\n",
    "        self.shell.user_ns = mod.__dict__\n",
    "\n",
    "        try:\n",
    "            for cell in nb.worksheets[0].cells:\n",
    "                if cell.cell_type == 'code' and cell.language == 'python':\n",
    "                    # transform the input to executable Python\n",
    "                    code = self.shell.input_transformer_manager.transform_cell(cell.input)\n",
    "                    # run the code in themodule\n",
    "                    exec(code, mod.__dict__)\n",
    "        finally:\n",
    "            self.shell.user_ns = save_user_ns\n",
    "        return mod\n",
    "\n",
    "\n",
    "class NotebookFinder(object):\n",
    "    \"\"\"Module finder that locates Jupyter Notebooks\"\"\"\n",
    "    def __init__(self):\n",
    "        self.loaders = {}\n",
    "\n",
    "    def find_module(self, fullname, path=None):\n",
    "        nb_path = find_notebook(fullname, path)\n",
    "        if not nb_path:\n",
    "            return\n",
    "\n",
    "        key = path\n",
    "        if path:\n",
    "            # lists aren't hashable\n",
    "            key = os.path.sep.join(path)\n",
    "\n",
    "        if key not in self.loaders:\n",
    "            self.loaders[key] = NotebookLoader(path)\n",
    "        return self.loaders[key]\n",
    "\n",
    "sys.meta_path.append(NotebookFinder())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from Print.ipynb\n",
      "('Printing runtime = ', 0.6023680000000002, ' s')\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Aug 17 12:57:50 2018\n",
    "\n",
    "@author: shahelkhan\n",
    "\n",
    "Plot.py\n",
    "\n",
    "Purpose:\n",
    "    - Almost stand alone module which plots the results to the rest of the program\n",
    "    - Loads the data form the stored files\n",
    "    \n",
    "\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.path as mpath\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "import Print\n",
    "\n",
    "start_time = time.clock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotMapCircular(address, address_fronts, run, n_comp, plotFronts=True):\n",
    "    print(\"Plot.plotMapCircular\")\n",
    "    # Load lat, lon and labels\n",
    "    lon, lat, varTime, labels = None, None, None, None\n",
    "    lon, lat, varTime, labels = Print.readLabels(address, run)\n",
    "    \n",
    "    # Plot the data in map form - individual\n",
    "    colorname = 'RdYlBu'\n",
    "    colormap = plt.get_cmap(colorname,n_comp)\n",
    "    \n",
    "#    proj = ccrs.Orthographic(central_longitude=0.0, central_latitude=-90.0, globe=None)\n",
    "    proj = ccrs.SouthPolarStereo()\n",
    "    proj_trans = ccrs.PlateCarree()\n",
    "    \n",
    "    ax1 = plt.axes(projection=proj)\n",
    "    CS = ax1.scatter(lon, lat, s = 0.5, lw = 0, c = labels, cmap=colormap, \\\n",
    "                     vmin = -0.5, vmax = n_comp-0.5, transform = proj_trans)\n",
    "    \n",
    "    if plotFronts:\n",
    "        SAF, SACCF, SBDY, PF = None, None, None, None\n",
    "        SAF, SACCF, SBDY, PF = loadFronts(address_fronts)     # Format is Lon col = 0 and Lat col = 1\n",
    "        \n",
    "        ax1.plot(SAF[:,0], SAF[:,1], lw = 1, ls='-', label='SAF', color='black', transform=proj_trans)\n",
    "        ax1.plot(SACCF[:,0], SACCF[:,1], lw = 1,ls='-', label='SACCF', color='green', transform=proj_trans)\n",
    "        ax1.plot(SBDY[:,0], SBDY[:,1], lw = 1,ls='-', label='SBDY', color='blue', transform=proj_trans)\n",
    "        ax1.plot(PF[:,0], PF[:,1], lw = 1,ls='-', label='PF', color='grey', transform=proj_trans)\n",
    "        \n",
    "        #ax1.legend(loc='upper left')\n",
    "        ax1.legend(bbox_to_anchor=( 1.25,1.2), ncol=4, columnspacing = 0.8)\n",
    "\n",
    "    # Compute a circle in axes coordinates, which we can use as a boundary for the map.\n",
    "    theta = np.linspace(0, 2*np.pi, 100)\n",
    "    center = [0.5, 0.5]\n",
    "    radius = 0.46   # 0.46 corresponds to roughly 30S Latitude\n",
    "    verts = np.vstack([np.sin(theta), np.cos(theta)]).T\n",
    "    circle = mpath.Path(verts * radius + center)\n",
    "\n",
    "    ax1.set_boundary(circle, transform=ax1.transAxes)\n",
    "    \n",
    "    # Add features\n",
    "    ax1.gridlines()\n",
    "#    ax1.add_feature(cfeature.LAND)\n",
    "    ax1.coastlines()\n",
    "    \n",
    "    colorbar = plt.colorbar(CS)\n",
    "    colorbar.set_label('Class', rotation=270, labelpad=10)\n",
    "    plt.savefig(address+\"Plots/Labels_Map_n\"+str(n_comp)+\".pdf\",bbox_inches=\"tight\",transparent=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadFronts(address_fronts):\n",
    "    SAF, SACCF, SBDY, PF = None, None, None, None\n",
    "    SAF =   np.loadtxt(address_fronts+'saf.txt')\n",
    "    SACCF = np.loadtxt(address_fronts+'saccf.txt')\n",
    "    SBDY =  np.loadtxt(address_fronts+'sbdy.txt')\n",
    "    PF =    np.loadtxt(address_fronts+'pf.txt')\n",
    "    \n",
    "    return SAF, SACCF, SBDY, PF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotPosterior(address, address_fronts, run, n_comp, plotFronts=True):\n",
    "    print(\"Plot.plotPosterior\")\n",
    "    # Load lat, lon and labels\n",
    "    lon, lat, varTime, labels = None, None, None, None\n",
    "    lon, lat, varTime, labels = Print.readLabels(address, run)\n",
    "\n",
    "    # Load the posterior probabilities for each class\n",
    "    class_number_array = None\n",
    "    class_number_array = np.arange(0,n_comp).reshape(-1,1)\n",
    "    lon_pp, lat_pp, varTime_pp, post_prob = Print.readPosteriorProb(address, run, class_number_array)\n",
    "\n",
    "    for k in class_number_array:\n",
    "        lon_k, lat_k, post_k, indices_k = None, None, None, None\n",
    "        indices_k = (np.where(labels == (1.0*k)))\n",
    "        lon_k, lat_k = lon[indices_k], lat[indices_k]\n",
    "        post_k = post_prob[:,k][indices_k]  \n",
    "            # Idea is to take one class, n, and select all indices_k that are actaully assigned to that class.\n",
    "        likelihood = np.zeros(len(post_k))\n",
    "        for i in range(len(post_k)):\n",
    "            if post_k[i] >= 0.99:\n",
    "                likelihood[i] = 0.99\n",
    "            elif post_k[i] >= 0.9 and post_k[i] < 0.99 :\n",
    "                likelihood[i] = 0.9\n",
    "            elif post_k[i] >= 0.66 and post_k[i] < 0.9:\n",
    "                likelihood[i] = 0.66\n",
    "            elif post_k[i] >= 1/(n_comp) and post_k[i] < 0.66:\n",
    "                likelihood[i] = 1/(n_comp)\n",
    "            else:\n",
    "                print(\"WARNING : Posterior Value less than 1/k\")\n",
    "        # Plot the posterior probabilites\n",
    "        ax = plt.subplot(111, polar=True)\n",
    "        colorname = 'RdYlBu'\n",
    "        colormap = plt.get_cmap(colorname, 4)\n",
    "        \n",
    "        theta = np.pi*(lon_k)/180.0\n",
    "        rho = 90 - abs(lat_k)\n",
    "        \n",
    "        CS = ax.scatter(theta,rho, 0.5, lw = 0, c = likelihood, cmap=colormap, vmin = 0, vmax = 1)\n",
    "\n",
    "        \n",
    "        if plotFronts:\n",
    "            SAF, SACCF, SBDY, PF = None, None, None, None\n",
    "            SAF, SACCF, SBDY, PF = loadFronts(address_fronts)     # Format is Lon col = 0 and Lat col = 1\n",
    "            \n",
    "            theta_saf = np.pi*(SAF[:,0])/180.0\n",
    "            rho_saf = 90 - abs(SAF[:,1])\n",
    "            ax.plot(theta_saf, rho_saf, lw = 1, ls='-', label='SAF', color='black')\n",
    "            \n",
    "            theta_saccf = np.pi*(SACCF[:,0])/180.0\n",
    "            rho_saccf = 90 - abs(SACCF[:,1])\n",
    "            ax.plot(theta_saccf, rho_saccf, lw = 1,ls='-', label='SACCF', color='green')\n",
    "            \n",
    "            theta_sbdy = np.pi*(SBDY[:,0])/180.0\n",
    "            rho_sbdy = 90 - abs(SBDY[:,1])\n",
    "            ax.plot(theta_sbdy, rho_sbdy, lw = 1,ls='-', label='SBDY', color='blue')\n",
    "            \n",
    "            theta_pf = np.pi*(PF[:,0])/180.0\n",
    "            rho_pf = 90 - abs(PF[:,1])\n",
    "            ax.plot(theta_pf, rho_pf, lw = 1,ls='-', label='PF', color='grey')\n",
    "            \n",
    "            #ax1.legend(loc='upper left')\n",
    "            ax.legend(bbox_to_anchor=( 1.25,1.25), ncol=4, columnspacing = 0.8)\n",
    "        \n",
    "        ax.set_theta_zero_location(\"N\")\n",
    "        ax.set_theta_direction(-1)\n",
    "        ax.set_ylim(0,60)\n",
    "        #ax.set_title(\"Class \"+str(k[0]), horizontalalignment='left')\n",
    "        plt.text(0, 1, \"Class \"+str(k[0]), transform = ax.transAxes)\n",
    "        ax.set_yticklabels([])\n",
    "        colorbar = plt.colorbar(CS)\n",
    "        colorbar.set_label('Probability of belonging to Class', rotation=270, labelpad=10)\n",
    "        plt.savefig(address+\"Plots/PostProb_Class\"+str(k[0])+\"_n\"+str(n_comp)+\".pdf\",bbox_inches=\"tight\",transparent=True)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotProfileClass(address, run, n_comp, space):\n",
    "    # space will be 'depth', 'reduced' or 'uncentred'\n",
    "    print(\"Plot.plotProfileClass \"+str(space))\n",
    "    # Load depth\n",
    "    depth = None\n",
    "    depth = Print.readDepth(address, run)\n",
    "    \n",
    "    # Load reduced depth\n",
    "    col_reduced = None\n",
    "    col_reduced = Print.readColreduced(address, run)\n",
    "    col_reduced_array = np.arange(col_reduced)\n",
    "    \n",
    "    #\n",
    "    depth_array = None\n",
    "    depth_array = depth\n",
    "    if space == 'reduced':\n",
    "        depth_array = col_reduced_array\n",
    "    \n",
    "    # Load class properties\n",
    "    gmm_weights, gmm_means, gmm_covariances = None, None, None\n",
    "    gmm_weights, gmm_means, gmm_covariances = Print.readGMMclasses(address,\\\n",
    "                                                        run, depth_array, space)\n",
    "    \n",
    "    fig, ax1 = plt.subplots()\n",
    "    for d in range(n_comp):\n",
    "        ax1.plot(gmm_means[d,:], depth_array, lw = 1, label = \"Class \"+str(d))\n",
    "        \n",
    "    if space == 'depth':\n",
    "        ax1.set_xlabel(\"Normalized Temperature Anomaly /degree\")\n",
    "        ax1.set_ylabel(\"Depth\")\n",
    "        ax1.set_xlim(-3,3)\n",
    "    elif space == 'uncentred':\n",
    "        ax1.set_xlabel(\"Temperature /degrees\")\n",
    "        ax1.set_ylabel(\"Depth\")\n",
    "    elif space == 'reduced':\n",
    "        ax1.set_xlabel(\"Normalized Anomaly\")\n",
    "        ax1.set_ylabel(\"Reduced Depth\")\n",
    "    ax1.invert_yaxis()\n",
    "    ax1.grid(True)\n",
    "    ax1.legend(loc='best')\n",
    "    #ax1.set_title(\"Class Profiles with Depth in SO - \"+space)\n",
    "    filename = address+\"Plots/Class_Profiles_\"+space+\"_n\"+str(n_comp)+\".pdf\"  \n",
    "    if run != None:\n",
    "        filename = address+\"Plots/Class_Profiles_\"+space+\"_run\"+str(int(run))+\"_n\"+str(n_comp)+\".pdf\"  \n",
    "    plt.savefig(filename,bbox_inches=\"tight\",transparent=True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotProfile(address, run, space): # Uses traing profiles at the moment\n",
    "        # space will be 'depth', 'original' or 'uncentred'\n",
    "    print(\"Plot.plotProfileClass \"+str(space))\n",
    "    # Load depth\n",
    "    depth = None\n",
    "    depth = Print.readDepth(address, run)\n",
    "    #\n",
    "    depth_array = None\n",
    "    depth_array = depth\n",
    "    X_profiles = None\n",
    "    if space == 'uncentred' or space == 'depth':\n",
    "        # Load profiles\n",
    "        lon_train, lat_train, X_train, X_train_centred, varTime_train = None, None, None, None, None\n",
    "        lon_train, lat_train, X_train, X_train_centred, varTime_train = \\\n",
    "                        Print.readReconstruction(address, run, depth, True)\n",
    "        \"\"\"\n",
    "        lon_train, lat_train, Tint_train_array, X_train_array, \\\n",
    "            Sint_train_array, varTime_train = None, None, None, None, None, None\n",
    "        lon_train,lat_train, Tint_train_array, X_train_array, \\\n",
    "            Sint_train_array, varTime_train = Print.readLoadFromFile_Train(address, run, depth)    \n",
    "        X_train_centred = X_train_array\n",
    "        \"\"\"\n",
    "        if space == 'uncentred':\n",
    "            X_profiles = X_train\n",
    "        if space == 'depth':\n",
    "            X_profiles = X_train_centred\n",
    "    elif space == 'original':\n",
    "        lon_train, lat_train, Tint_train_array, X_train_array, \\\n",
    "            Sint_train_array, varTime_train = None, None, None, None, None, None\n",
    "        lon_train, lat_train, Tint_train_array, X_train_array, \\\n",
    "            Sint_train_array, varTime_train = Print.readLoadFromFile_Train(address, run, depth)\n",
    "        \n",
    "        X_profiles = Tint_train_array\n",
    "    \n",
    "    fig, ax1 = plt.subplots()\n",
    "    for d in range(np.ma.size(X_profiles, axis=0)):\n",
    "        ax1.plot(X_profiles[d,:], depth_array, lw = 1, alpha = 0.01, color = 'grey')\n",
    "        \n",
    "    if space == 'depth':\n",
    "        ax1.set_xlabel(\"Normalized Temperature Anomaly /degree\")\n",
    "        ax1.set_ylabel(\"Depth\")\n",
    "    elif space == 'uncentred':\n",
    "        ax1.set_xlabel(\"Temperature /degrees\")\n",
    "        ax1.set_ylabel(\"Depth\")\n",
    "    ax1.invert_yaxis()\n",
    "    ax1.grid(True)\n",
    "    ax1.legend(loc='best')\n",
    "    #ax1.set_title(\"Profiles with Depth in SO - \"+space)\n",
    "    ax1.set_xlabel(\"Temperature /degrees\")\n",
    "    ax1.set_ylabel(\"Depth /dbar\")\n",
    "    filename = address+\"Plots/Profiles_\"+space+\".pdf\"  \n",
    "    if run != None:\n",
    "        filename = address+\"Plots/Profiles_\"+space+\"_run\"+str(int(run))+\".pdf\"  \n",
    "    plt.savefig(filename,bbox_inches=\"tight\",transparent=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotGaussiansIndividual(address, run, n_comp, space, Nbins=1000):\n",
    "    # space will be 'depth', 'reduced' or 'uncentred'\n",
    "    print(\"Plot.plotGaussiansIndividual \"+str(space))\n",
    "    if space == 'depth' or space == 'uncentred':\n",
    "        # Load depth\n",
    "        depth = None\n",
    "        depth = Print.readDepth(address, run)\n",
    "        depth_array = depth\n",
    "        print(\"depth.shape = \", depth.shape)\n",
    "        depth_array_mod = np.array([0,50,100,150,-1])\n",
    "        print(\"depth_array_mod.shape = \", depth_array_mod.shape)\n",
    "        \n",
    "        # Load X_train array and X_train_centred array\n",
    "        lon_train, lat_train, X_train, X_train_centred, varTime_train = None, None, None, None, None\n",
    "        lon_train, lat_train, X_train, X_train_centred, varTime_train = \\\n",
    "                        Print.readReconstruction(address, run, depth, True)\n",
    "        \"\"\"\n",
    "        lon_train, lat_train, Tint_train_array, X_train_array, \\\n",
    "            Sint_train_array, varTime_train = None, None, None, None, None, None\n",
    "        lon_train,lat_train, Tint_train_array, X_train_array, \\\n",
    "            Sint_train_array, varTime_train = Print.readLoadFromFile_Train(address, run, depth)    \n",
    "        X_train_centred = X_train_array\n",
    "        \"\"\"\n",
    "        print(\"VALUE = \", X_train_centred[10,0])\n",
    "        \n",
    "    if space == 'reduced':\n",
    "        # Load reduced depth\n",
    "        col_reduced = None\n",
    "        col_reduced = Print.readColreduced(address, run)\n",
    "        depth_array = np.arange(col_reduced)\n",
    "        depth_array_mod = depth_array\n",
    "        \n",
    "        lon_train, lat_train, X_train_centred, varTime_train = None, None, None, None\n",
    "        lon_train, lat_train, X_train_centred, varTime_train = \\\n",
    "                        Print.readPCAFromFile_Train(address, run, col_reduced)\n",
    "        print(\"VALUE = \", X_train_centred[10,0])\n",
    "    \n",
    "    # Load class properties\n",
    "    gmm_weights, gmm_means, gmm_covariances = None, None, None\n",
    "    gmm_weights, gmm_means, gmm_covariances = Print.readGMMclasses(address,\\\n",
    "                                                        run, depth_array, space)\n",
    "    if space == 'uncentred':\n",
    "        stand = None\n",
    "        with open(address+\"Objects/Scale_object.pkl\", 'rb') as input:\n",
    "            stand = pickle.load(input)\n",
    "        gmm_means = stand.inverse_transform(gmm_means)\n",
    "        gmm_covariances = stand.inverse_transform(gmm_covariances)\n",
    "\n",
    "    print(\"Shapes: \", gmm_weights.shape, gmm_means.shape, gmm_covariances.shape)\n",
    "    print(\"depth_array_mod.shape = \", depth_array_mod.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the gaussian function\n",
    "def gaussianFunc(x, mu, cov):\n",
    "    return (np.exp(-np.power(x - mu, 2.) / (2 * cov)))/(np.sqrt(cov*np.pi*2))\n",
    "\n",
    "    for i in range(len(depth_array_mod)):\n",
    "        print(\"About to plot\")\n",
    "        X_row = None\n",
    "        X_row = X_train_centred[:,int(depth_array_mod[i])]\n",
    "        if space == 'uncentred':\n",
    "            X_row = None\n",
    "            X_row = X_train[:,int(depth_array_mod[i])]\n",
    "        means_row, cov_row = None, None\n",
    "        means_row = gmm_means[:,int(depth_array_mod[i])]\n",
    "        cov_row = abs(gmm_covariances[:,int(depth_array_mod[i])])\n",
    "        print(\"Covariance = \", cov_row)\n",
    "\n",
    "        xmax, xmin = None, None\n",
    "        xmax = np.max(X_row)*1.1\n",
    "        xmin = np.min(X_row)*1.1\n",
    "\n",
    "        print(\"Xmin = \", xmin, \"Xmax = \", xmax)\n",
    "\n",
    "        fig, ax1 = plt.subplots()\n",
    "        x_values = None\n",
    "        x_values = np.linspace(xmin, xmax, 120)\n",
    "        print(x_values.shape, min(x_values), max(x_values))\n",
    "\n",
    "        y_total = np.zeros(n_comp*120).reshape(n_comp,120)\n",
    "\n",
    "        for n in range(n_comp):\n",
    "            y_gaussian = None\n",
    "    #            y_gaussian = gmm_weights[n]*gaussianFunc(x_values, gmm_means[n,int(depth_array_mod[i])] , gmm_covariances[n,int(depth_array_mod[i])]) # Use if diag\n",
    "            y_gaussian = gmm_weights[n]*gaussianFunc(x_values, means_row[n] , cov_row[n]) # Use if diag\n",
    "            y_total[n,:] = y_gaussian\n",
    "            ax1.plot(x_values, y_gaussian, label=str(n))\n",
    "\n",
    "\n",
    "        ax1.plot(x_values, np.sum(y_total,axis=0), lw = 2, color = 'black', label=\"Overall\")     # Use if diag\n",
    "        ax1.hist(X_row, bins=Nbins, normed=True, facecolor='grey', lw = 0)\n",
    "        ax1.set_ylabel(\"Probability density\")\n",
    "        ax1.set_xlabel(\"Normalized Temperature Anomaly\")\n",
    "        if space == 'reduced':\n",
    "            ax1.set_xlabel(\"Normalized Anomaly\")\n",
    "        if space == 'uncentred':\n",
    "            ax1.set_xlabel(\"Temperature /degrees\")\n",
    "        ax1.set_title(\"GMM n = \"+str(n_comp)+\", \"+space+\" = \"+str(int(depth_array[depth_array_mod[i]])))\n",
    "        ax1.grid(True)\n",
    "        ax1.set_xlim(xmin,xmax)\n",
    "        ax1.legend(loc='best')\n",
    "        plt.savefig(address+\"Plots/TrainHisto_Gaussians_n\"+str(n_comp)+\"_\"+space+str(int((depth_array[depth_array_mod[i]])))+\".pdf\",bbox_inches=\"tight\",transparent=True)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotBIC(address, repeat_bic, max_groups, trend=True): \n",
    "    # Load the data and define variables first\n",
    "    bic_many, bic_mean, bic_stdev, n_mean, n_stdev, n_min = None, None, None, None, None, None\n",
    "    bic_many, bic_mean, bic_stdev, n_mean, n_stdev, n_min = Print.readBIC(address, repeat_bic)\n",
    "    n_comp_array = None\n",
    "    n_comp_array = np.arange(1, max_groups)\n",
    "    \n",
    "    print(\"Calculating n and then averaging across runs, n = \", n_mean, \"+-\", n_stdev)\n",
    "    print(\"Averaging BIC scores and then calculating, n = \", n_min)\n",
    "    \n",
    "    # Plot the results\n",
    "    fig, ax1 = plt.subplots()\n",
    "    ax1.errorbar(n_comp_array, bic_mean, yerr = bic_stdev, lw = 2, ecolor = 'black', label = 'Mean BIC Score')\n",
    "    \n",
    "    if trend:\n",
    "        # Plot the trendline\n",
    "        #initial_guess = [20000, 1, 20000, 0.001]\n",
    "        initial_guess = [47030, 1.553, 23080, 0.0004652]\n",
    "        def expfunc(x, a, b, c, d):\n",
    "            return (a * np.exp(-b * x)) + (c * np.exp(d * x))\n",
    "        \n",
    "        popt, pcov, x, y = None, None, None, None\n",
    "        popt, pcov = curve_fit(expfunc, n_comp_array, bic_mean, p0 = initial_guess, maxfev=10000)\n",
    "        print(\"Exponential Parameters = \", popt)\n",
    "        x = np.linspace(1, max_groups, 100)\n",
    "        y = expfunc(x, popt)\n",
    "        ax1.plot(x, y, 'r-', label=\"Exponential Fit\")\n",
    "        \n",
    "        y_min_index = np.where(y==y.min())[0]\n",
    "        x_min = (x[y_min_index])[0]\n",
    "        ax1.axvline(x=x_min, linestyle=':', color='black', label = 'Exponential Fit min = '+str(np.round_(x_min, decimals=1)))\n",
    "\n",
    "\n",
    "    # Plot the individual and minimum values\n",
    "    ax1.axvline(x=n_mean, linestyle='--', color='black', label = 'n_mean_min = '+str(n_mean))\n",
    "    ax1.axvline(x=n_min, linestyle='-.', color='black', label = 'n_bic_min = '+str(n_min))\n",
    "    for r in range(repeat_bic):\n",
    "        ax1.plot(n_comp_array, bic_many[r,:], alpha = 0.3, color = 'grey')\n",
    "        \n",
    "    ax1.set_ylabel(\"BIC value\")\n",
    "    ax1.set_xlabel(\"Number of classes in GMM\")\n",
    "    ax1.grid(True)\n",
    "    ax1.set_title(\"BIC values for GMM with different number of components\")\n",
    "    ax1.set_ylim(min(bic_mean)*0.97, min(bic_mean)*1.07)\n",
    "    ax1.legend(loc='best')\n",
    "    if trend:\n",
    "        plt.savefig(address+\"Plots/BIC_trend.pdf\",bbox_inches=\"tight\",transparent=True)\n",
    "    else:\n",
    "        plt.savefig(address+\"Plots/BIC.pdf\",bbox_inches=\"tight\",transparent=True)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Plot runtime = ', 0.7217000000000002, ' s')\n"
     ]
    }
   ],
   "source": [
    "# Use the VBGMM to determine how many classes we should use in the GMM\n",
    "def plotWeights(address, run):\n",
    "    # Load depth\n",
    "    depth = None\n",
    "    depth = Print.readDepth(address, run)\n",
    "\n",
    "    # Load Weights    \n",
    "    gmm_weights, gmm_means, gmm_covariances = None, None, None\n",
    "    gmm_weights, gmm_means, gmm_covariances = Print.readGMMclasses(address, run, depth, 'depth')\n",
    "    \n",
    "    n_comp = len(gmm_weights)\n",
    "    class_array = np.arange(0,n_comp,1)\n",
    "    \n",
    "    # Plot weights against class number\n",
    "    fig, ax1 = plt.subplots()\n",
    "    ax1.scatter(class_array, np.sort(gmm_weights)[::-1], s = 20, marker = '+', color = 'blue', label = 'Class Weights')\n",
    "    ax1.axhline(y=1/(n_comp+1), linestyle='-.', color='black', label = str(np.round_(1/(n_comp+1), decimals=3))+' threshold')\n",
    "    ax1.axhline(y=1/(n_comp+5), linestyle='--', color='black', label = str(np.round_(1/(n_comp+5), decimals=3))+' threshold')\n",
    "    ax1.set_xlabel(\"Class\")\n",
    "    ax1.set_xlim(-1,n_comp)\n",
    "    ax1.set_ylabel(\"Weight\")\n",
    "    ax1.grid(True)\n",
    "    ax1.set_title(\"VBGMM Class Weights\")\n",
    "    ax1.legend(loc='best')\n",
    "    plt.savefig(address+\"Plots/Weights_VBGMM.pdf\", bbox_inches=\"tight\",transparent=True)\n",
    "    \n",
    "    \n",
    "print('Plot runtime = ', time.clock() - start_time,' s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
